
OLAP Processing and Benchmarking on Yelp Dataset
-------------------------------------------------------------------------------
TEAM
-------------------------------------------------------------------------------

    * Sreemukha Taduru, staduru, staduru, staduru (Lead). 
    * Sravya Panganamamula, vpangana, vpangana, sravyasai.
    * Harish Reddy Nallagangireddygari, hnallaga, hnallaga, harish

-------------------------------------------------------------------------------
DESCRIPTION
-------------------------------------------------------------------------------
This project is about performing preprocessing on Yelp Dataset using Apache PIG. We will be running pig scripts on yelp dataset with different configurations by varying the number of reducers to perform benchmarking. The goal of the project is to obtain the run time of these pig scripts with varying configurations.
    
-------------------------------------------------------------------------------
PROBLEM STATEMENT
-------------------------------------------------------------------------------
In this project, we are running pig scripts on yelp dataset to process the data. The dataset is loaded into the Hadoop virtual instances using ansible. We have written scripts on different JSON files and converted them into a .tsv format. In addition, we have performed both join and aggregation on the yelp dataset using pig scripts. We have also varied the number reducers in these scripts to compare the run time before and after changing these parameters. 

The primary goal of this project is to perform benchmarking on yelp dataset. Benchmarking is an important means by which the performance of a system can be measured. In this project, we have benchmarked the running time of these scripts on different JSON files present in the yelp dataset.

We initially planned to write HIVE queries, but realized that the dataset requires lots of preprocessing as it is in JSON format. We have therefore written pig scripts to preprocess and perform different functions such as join, aggregation, filter, etc. on the data. However, we have performed benchmarking on yelp dataset which is the primary style of this project. 

-------------------------------------------------------------------------------
Apache Pig
-------------------------------------------------------------------------------
Pig is a platform for analyzing large datasets. It contains high-level language for expressing data analysis programs. An impressive property of a pig program is that it is capable of substantial parallelization. Therefore, it handles large datasets effectively. Since the yelp dataset is fairly large and requires a lot of preprocessing, we have chosen to use PIG in our project. 

At the infrastructure layer, pig consists of a compiler that creates or produces sequences of Map-Reduce Programs. Large-scale parallel implementations already exist for these programs. In addition, pigâ€™s language layer uses a language known as Pig Latin which brings with it the ease of programming, optimization and extensibility.  

Also, it is easy to set default parallelism i.e. to set number of reducers in pig scripts. However, the number of mappers depend on the number of file splits. These splits depend on the size of the block into which HDFS splits the files.  

-------------------------------------------------------------------------------
IMPLEMENTATION
-------------------------------------------------------------------------------
There are 4 pig scripts that have been written on yelp dataset. 

  * First script converts the review json file into .tsv by generating tabs of different fields.
  * An aggregate script that groups reviews by user id, counts the users and stores the result in .tsv format
  * A join script that joins reviews and users json file by user id and stores the results in .tsv format
  * A filter script that filters out reviews that have greater than an average of 4 stars and stores the results in .tsv format.

All these scripts were run with default configuration as well as with number of reducers set to 5 multiple times. The results obtained are discussed below. We have written a shell script main.sh that that automates the execution of all these scripts one after the other. The shell script also removes the .tsv files generated by the scripts in order to save memory and avoid exceptions the next time scripts are run. 

To run the project, the following steps should be taken. 

Pull the code from the git repository by using the following command in any local repository where
this needs to be executed


    git pull https://github.iu.edu/staduru/sw-project-template.git
    
To run the project, kindly follow the steps in `installation.rst file <installation.rst>`_.

Change directory to src folder and run the launch.sh script as shown:
    
    cd src
    source launch.sh

This will run the ansible playbook to create three virtual instances and installs the Hadoop cluster with one name node and two data nodes. It then installs Pig on these virtual machines and downloads and extracts the yelp dataset into HDFS of the instance. It also deploys the required pig scripts and the main.sh shell script which further runs the pig scripts one after the other. Once the launch.sh completes its execution, ssh into the frontendnode of the created instances using the following command.
    
    ssh hadoop@<master 0 ip address>

The ip address can be found using ``nova list`` command.

After ssh into hadoop, the following commands should be used:

    bash
    source main.sh


-------------------------------------------------------------------------------
RESULTS
-------------------------------------------------------------------------------
The following results were obtained after running the above pig scripts. Note that the results obtained were different everytime the scripts were run. The initial results are as follows:
Find the `screenshots<Images>_` of the results obtained.

    Converting yelp_dataset_academic_review.json to yelp_dataset_academic_review.tsv
    
    * Default Configuration (2 reducers): 8 minutes, 21 seconds, 203 milliseconds. 
    * 5 Reducers: 1 minute, 45 seconds, 957 milliseconds
    
    Aggregation using group by
    
    * Default Configuration (2 reducers): 12 minutes, 14 seconds, 140 milliseconds. 
    * 5 Reducers: 2 minutes, 17 second, 444 milliseconds.


    Join script
    
    * Default Configuration (2 reducers): 2 minutes, 26 seconds, 771 milliseconds.
    * 5 Reducers: 2 minutes, 51 seconds, 169 milliseconds.
    
    Filter script
  
    * Default Configuration (2 reducers): 31 seconds, 326 milliseconds.
    * 5 Reducers: 25 seconds, 606 milliseconds.
    
-------------------------------------------------------------------------------
Findings
-------------------------------------------------------------------------------

After running the scripts, we found that the run time of the scripts improved considerably by changing the number of reducers compared to default configuration. The default configuration was with parallelism 2 (2 reducers). We have executed the scripts with parallelism 5 (5 reducers) and obtained the above results. It was also found that the configuration did not change for the 1st and 4th scripts described in the above section. 

Also, the run time varied every time the script was run. There were no stable run times obtained for the scripts i.e. the run times changed with every run.  

-------------------------------------------------------------------------------
REFERENCES
-------------------------------------------------------------------------------

   [1] https://pig.apache.org/
   [2] http://blog.cloudera.com/blog/2015/07/how-to-tune-mapreduce-parallelism-in-apache-pig-jobs/
   [3] https://hadoopjournal.wordpress.com/2015/05/30/set-reducers-in-pig-hive-and-mapreduce/
   [4] http://www.tutorialspoint.com/apache_pig/pig_latin_basics.htm
   [5] https://pig.apache.org/docs/r0.11.1/perf.html
   [6] http://blog.cloudera.com/blog/2015/07/how-to-tune-mapreduce-parallelism-in-apache-pig-jobs/

